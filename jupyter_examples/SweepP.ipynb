{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433c42d8-ce3e-4297-9a63-7ccef4d4aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9398a2-7814-4c21-87d2-23827e41dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_sim\n",
    "tree_sim.EXPIRATION_TIME = 1e2 # we use 1e3 in the paper but that makes the sim take way too long to play with in a notebook\n",
    "tree_sim.MEMORIES_PER_END_NODE=50 # recommended \"sane\" range is 20 to 100.  We use 10 in the paper, but that goes with the longer expiration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a4cb3a-8131-4df3-b789-1292bcb35930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb0cfaa-d6dc-47db-ac16-d6b66eefabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b9c19e-9e0f-4959-880f-5a2a96ca3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a001c1a4-6982-45eb-83db-c3dd2c03e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "from shutil import rmtree\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88358e38-06a2-481e-bccf-bda1aff5f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = \"jupyter_example_data/sweep\"\n",
    "pool = Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79160997-833d-4f96-9c84-78b4e41db48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation:\n",
      "n: The number of layers of the tree.\n",
      "k: The branching factor the tree.\n",
      "b: The word size of requests.\n",
      "samples: The number of samples taken for averaging.  At samples=11 it will instead sample until convergence.\n",
      "N = k^(n-1) is the number of client nodes served by the tree.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06742d205e4043d79a5bd9d600b87b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='n', max=4, min=2), IntSlider(value=3, description='k', mâ€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_sim_with_size(n, k, b, samples):\n",
    "    try:\n",
    "        rmtree(dir_str)\n",
    "    except:\n",
    "        pass\n",
    "    os.makedirs(dir_str)\n",
    "    l=cpu_count()\n",
    "    if samples == 11:\n",
    "        samples = True\n",
    "        print(\"WARNING: Sampling until convergence.  Expect long runtimes (on the order of minutes)\")\n",
    "    elif samples == 0:\n",
    "        samples = False\n",
    "        \n",
    "    params = [{\"p\" : 0.1**(1+2*i/l), \"k\" : 3, \"n\" : n, \"t\" : \"2e3\", \"b\" : b, \"resample\" : samples} for i in range(l)]\n",
    "    for result in tqdm(pool.imap_unordered(tree_sim.launch_sim_from_dict, params), total=l):\n",
    "        os.makedirs(os.path.join(dir_str, f\"n_{result['init_data'][2]}\"), exist_ok=True) # The data is organized into subfolders based on the value of n.\n",
    "        with open(os.path.join(dir_str, f\"n_{result['init_data'][2]}/{result['init_data']}.data\"), \"wb\") as f: # Each individual simulation has a data file, with a name based on its parameters.\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "    plotdict = {\n",
    "            \"x\" : \"p\",\n",
    "            \"y\" : \"rate\",\n",
    "            \"indir\" : dir_str,\n",
    "            \"legend\" : True,\n",
    "            }\n",
    "    plot_sim_results.make_plot_from_dict(plotdict)\n",
    "\n",
    "print(\"Explanation:\")\n",
    "print(\"n: The number of layers of the tree.\")\n",
    "print(\"k: The branching factor the tree.\")\n",
    "print(\"b: The word size of requests.\")\n",
    "print(\"samples: The number of samples taken for averaging.  At samples=11 it will instead sample until convergence.\")\n",
    "print(\"N = k^(n-1) is the number of client nodes served by the tree.\")\n",
    "interactive_sim = ipywidgets.interactive(run_sim_with_size, n=ipywidgets.IntSlider(3, 2, 4, 1), k=ipywidgets.IntSlider(3,2,4,1), b=ipywidgets.IntSlider(3,1,8,1), samples=ipywidgets.IntSlider(5,1,11,1))\n",
    "interactive_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e14084-c57c-418e-8e0c-10dbd14644e2",
   "metadata": {},
   "source": [
    "Note that the network is *scalable* in that the saturation point (when performance starts to seriously decay) is independent of the size of the network (n and k).  Word size does affect the saturation point.  This can be alleviated by increasing the number of memories at each step linearly with the word size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7393cf1-77f8-4235-8ca7-26b5a97a5148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
